% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/power.R
\name{assess_operating_characteristics}
\alias{assess_operating_characteristics}
\alias{run_power_iteration}
\title{Assess Operating Characteristics for One Iteration}
\usage{
assess_operating_characteristics(
  iter_num,
  data_paths,
  output_path,
  fit_functions,
  sample_size = 250,
  allocation_ratio = 0.5,
  seed = 123,
  rerandomize = FALSE,
  id_var = "id",
  tx_var = "tx"
)

run_power_iteration(
  iter_num,
  data_paths,
  output_path,
  fit_functions,
  sample_size = 250,
  allocation_ratio = 0.5,
  seed = 123,
  rerandomize = FALSE,
  id_var = "id",
  tx_var = "tx"
)
}
\arguments{
\item{iter_num}{Integer. Iteration number for tracking.}

\item{data_paths}{Named list of paths to datasets. Names must match those in
fit_functions. Example:
\code{list(markov = "ha_or_0.8.parquet", t_test = "t_data_or_0.8.parquet")}.}

\item{output_path}{Character. Path to directory where results will be saved
(required). Two subdirectories will be created:
\itemize{
\item \verb{summary/analysis_name/}: (Deprecated) Summary statistics (first element of fit function return)
\item \verb{details/analysis_name/}: Additional results (remaining elements of fit function return)
}}

\item{fit_functions}{Named list of functions that fit models and return results.
Each function receives \code{data} (sampled data) and \code{iter} (iteration number)
arguments. Must return a \strong{list} where:
\itemize{
\item First element: A one-row tibble/data frame with summary statistics containing
columns: \code{iter}, \code{analysis}, \code{se_type}, \code{term}, \code{estimate}, \code{std_error},
\code{statistic}, \code{p_value}, \code{conf_low}, \code{conf_high}. Saved to
\code{output_path/summary/analysis_name/analysis_name_iter_N.rds}.
\item Remaining elements (optional): Additional results to save to disk (e.g.,
bootstrap distributions, SOPs, detailed model output). Saved to
\code{output_path/details/analysis_name/analysis_name_iter_N.rds}.
}}

\item{sample_size}{Integer. Total number of patients to sample (default: 250).}

\item{allocation_ratio}{Numeric. Proportion assigned to treatment (default: 0.5).}

\item{seed}{Integer. Base random seed (default: 123). Actual seed will be
\code{seed + iter_num}.}
}
\value{
A tibble combining results from all analysis functions with columns:
\itemize{
\item iter: Iteration number
\item analysis: Analysis type
\item se_type: Type of standard error ("naive", "boot", etc.)
\item term: Coefficient name
\item estimate: Point estimate
\item std_error: Standard error
\item statistic: Test statistic
\item p_value: P-value
\item conf_low, conf_high: Confidence interval
}
}
\description{
Executes a complete simulation iteration by sampling patients once, then
applying multiple fitting functions to the same sample. Bootstrap inference
is handled within individual fitting functions, not by this orchestrator.
}
\details{
This function implements the correct simulation structure for assessing
operating characteristics (power, Type I error, bias, coverage):
\enumerate{
\item \strong{Iteration-level sampling}: Draws a fixed sample of patients from the
superpopulation for this iteration (using \code{seed + iter_num})
\item \strong{Multiple analyses}: Applies all fitting functions to the \emph{same} sample
\item \strong{Within-analysis inference}: Individual fitting functions handle their
own inference strategy (naive SEs, robust SEs, bootstrap, etc.)
\item \strong{Save additional results}: If fitting functions return more than just
summary statistics, additional results are saved to disk as RDS files
}

\strong{Key principle}: Each iteration gets a different sample from the superpopulation,
but all analyses within an iteration see the same sample. This allows fair
comparison of different methods on identical data.

\strong{Fitting function requirements}:
Each function should:
\enumerate{
\item Accept \code{data} (the sampled dataset) and \code{iter} (iteration number)
\item Perform any necessary data preparation
\item Fit the model (with or without bootstrap, as appropriate)
\item Return a \strong{list} where:
\itemize{
\item First element: One-row tibble with summary statistics
\item Remaining elements (optional): Additional data to save (bootstrap samples,
SOPs, detailed output, etc.)
}
}

\strong{File saving}:
The function saves results to two separate directory structures:
\enumerate{
\item \strong{Summary results} (first list element) (Deprecated): Saved to
\code{output_path/summary/analysis_name/analysis_name_iter_N.rds}
\item \strong{Additional results} (remaining list elements): Saved to
\code{output_path/details/analysis_name/analysis_name_iter_N.rds}
}

The details file contains a list with \code{results[-1]} (all elements except the
first). Both directory structures are created recursively as needed.

\strong{Bootstrap handling}: Bootstrap inference (if needed) should be implemented
within individual fitting functions, not by this orchestrator. This design:
\itemize{
\item Keeps parallelization simple (across iterations only)
\item Allows complete control over inference within each analysis
\item Avoids nested parallelization issues
}

\strong{Parallelization strategy}: The typical workflow is to parallelize across
simulation iterations:

\if{html}{\out{<div class="sourceCode r">}}\preformatted{library(furrr)
plan(multisession, workers = 8)
results <- future_map_dfr(
  1:1000,
  ~assess_operating_characteristics(iter_num = ., ...),
  .options = furrr_options(seed = TRUE)
)
}\if{html}{\out{</div>}}
}
\examples{
\dontrun{
# Define fitting functions that receive sampled data

# Markov analysis with bootstrap - returns list with summary + bootstrap details
fit_markov_boot <- function(data, iter) {
  model_data <- prepare_markov_data(data, absorbing_state = 6)

  # Fit model
  fit <- vglm(
    y ~ tx + rcs(time, 4) + yprev,
    family = cumulative(parallel = TRUE, reverse = TRUE),
    data = model_data
  )

  # Bootstrap within this function
  boot_coef <- bootstrap_model_coefs(
    fit,
    data = model_data,
    n_boot = 100,
    id_var = "id"
  )

  # Tidy bootstrap results and add required columns
  tidy_bootstrap_coefs(boot_coef, probs = c(0.025, 0.975), estimate = "median") |>
    filter(term == "tx") |>
    mutate(
      iter = iter,
      analysis = "markov",
      se_type = "boot",
      # Calculate bootstrap SE from confidence limits (approximate)
      std_error = NA_real_,
      statistic = NA_real_,
      p_value = NA_real_,
      conf_low = lower,
      conf_high = upper,
      .before = 1
    ) |>
    select(iter, analysis, se_type, term, estimate, std_error,
           statistic, p_value, conf_low, conf_high)

  # Return list: summary + additional results to save
  list(
    summary_results,
    list(
      boot_coefs = boot_coef,
      model_fit = fit
    )
  )
}

# T-test analysis (no additional results) - returns list with just summary
fit_ttest <- function(data, iter) {
  t_result <- t.test(y ~ tx, data = data)

  summary_results <- tibble(
    iter = iter,
    analysis = "t_test",
    se_type = "naive",
    term = "tx",
    estimate = -diff(t_result$estimate),
    std_error = t_result$stderr,
    statistic = t_result$statistic,
    p_value = t_result$p.value,
    conf_low = -t_result$conf.int[2],
    conf_high = -t_result$conf.int[1]
  )

  # Return list with just summary (no additional results to save)
  list(summary_results)
}

# Parallelize across iterations - each gets different sample
library(furrr)
plan(multisession, workers = 8)
results <- future_map_dfr(
  1:1000,
  ~assess_operating_characteristics(
    iter_num = .,
    data_paths = list(
      markov = "ha_or_0.8.parquet",
      t_test = "t_data_or_0.8.parquet"
    ),
    output_path = "power_sim_results",
    sample_size = 250,
    fit_functions = list(
      markov = fit_markov_boot,
      t_test = fit_ttest
    ),
    seed = 123
  ),
  .options = furrr_options(seed = TRUE, packages = c("rms", "VGAM", "dplyr"))
)
}

}
